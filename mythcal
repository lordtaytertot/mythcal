#! /usr/bin/python -W ignore

# mythcal

# Copyright 2009 Richard Fearn
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

CONFIG_FILE = "mythcal.conf"
CACHE_FILE = "mythcal.cache"

DATE_FORMAT = "%Y-%m-%d"
DATE_TIME_FORMAT = "%Y-%m-%dT%H:%M:%S.000Z"

import ConfigParser
from optparse import Values

import MySQLdb
from datetime import datetime
import pickle
import os
import smtplib
from email.mime.text import MIMEText

import gdata.calendar.service
import atom
import time

config = ConfigParser.RawConfigParser()
config.read(CONFIG_FILE)

settings = Values({
        "database": Values({
                "host": config.get("database", "host"),
                "name": config.get("database", "name"),
                "user": config.get("database", "user"),
                "password": config.get("database", "password")
        }),
        "google": Values({
                "username": config.get("google", "username"),
                "password": config.get("google", "password")
        }),
        "calendar": Values({
                "name": config.get("calendar", "name"),
                "id": config.get("calendar", "id")
        })
})

# see http://www.mythtv.org/wiki/Record_table
def load_recordings_from_database(db):
    """Loads recordings from the MythTV database."""
    cursor = db.cursor()
    cursor.execute("SELECT type, station, UNIX_TIMESTAMP(ADDTIME(startdate, starttime)), UNIX_TIMESTAMP(ADDTIME(enddate, endtime)), title, description FROM record ORDER BY startdate, starttime")
    result = cursor.fetchall()
    return [{"title": r[4], "channel": r[1], "start": datetime.utcfromtimestamp(r[2]), "end": datetime.utcfromtimestamp(r[3]), "description": r[5]} for r in result]

# Load recordings from MythTV database
db = MySQLdb.connect(host=settings.database.host, db=settings.database.name, user=settings.database.user, passwd=settings.database.password)
recordings = load_recordings_from_database(db)
current_time = datetime.utcnow()
past_recs = [r for r in recordings if r["end"] < current_time]
current_recs = [r for r in recordings if r["start"] <= current_time and current_time < r["end"]]
future_recs = [r for r in recordings if current_time < r["start"]]
recordings = {"past": past_recs, "current": current_recs, "future": future_recs}

# load recording list from last time
last_recordings = None
if os.path.exists(CACHE_FILE):
    f = open(CACHE_FILE, "r")
    last_recordings = pickle.load(f)
    f.close()

# update calendar, and output new recording list, if different
if recordings != last_recordings:

    # get calendar service and log in
    calendar_service = gdata.calendar.service.CalendarService()
    calendar_service.email = settings.google.username
    calendar_service.password = settings.google.password
    calendar_service.source = "mythcal"
    calendar_service.ProgrammaticLogin()

    # get MythTV calendar
    calendars_feed = calendar_service.GetOwnCalendarsFeed()
    cal = (c for c in calendars_feed.entry if c.title.text == settings.calendar.name).next()
    batch_url = "http://www.google.com/calendar/feeds/%s/private/full/batch" % settings.calendar.id

    # batch request
    request_feed = gdata.calendar.CalendarEventFeed()

    # add a delete entry for all events in the calendar
    event_feed = calendar_service.GetCalendarEventFeed(cal.content.src)
    for event in event_feed.entry:
        event.batch_id = gdata.BatchId(text="delete-request")
        request_feed.AddDelete(entry=event)

    def create_event(title, start, end, content=None):
        event = gdata.calendar.CalendarEventEntry()
        event.title = atom.Title(text=title)
        if content:
            event.content = atom.Content(text=content)
        event.when.append(gdata.calendar.When(start_time=start, end_time=end))
        return event

    def create_all_day_event(title, start, end, content=None):
        event_start = time.strftime(DATE_FORMAT, start)
        event_end = time.strftime(DATE_FORMAT, end)
        return create_event(title=title, start=event_start, end=event_end, content=content)

    def create_programme_event(title, channel, start, end, content=None):
        event_title = "%s (%s)" % (title, channel)
        event_start = time.strftime(DATE_TIME_FORMAT, start)
        event_end = time.strftime(DATE_TIME_FORMAT, end)
        return create_event(title=event_title, start=event_start, end=event_end, content=content)

    # add an event for current/future recordings
    for prog in recordings["current"] + recordings["future"]:
        event = create_programme_event(prog["title"], prog["channel"], prog["start"].timetuple(), prog["end"].timetuple(), prog["description"])
        event.batch_id = gdata.BatchId(text="insert-request")
        request_feed.AddInsert(entry=event)

    # add 'last updated' event
    last_update_text = "MythTV updated %s" % time.strftime("%H:%M", time.localtime())
    event = create_all_day_event(title=last_update_text, start=time.gmtime(), end=time.gmtime(time.time() + 24*60*60))
    event.batch_id = gdata.BatchId(text="insert-request")
    request_feed.AddInsert(entry=event)

    # submit batch request
    response_feed = calendar_service.ExecuteBatch(request_feed, batch_url)
    # for entry in response_feed.entry:
    #     print "%s; status %s; reason %s" % (entry.batch_id.text, entry.batch_status.code, entry.batch_status.reason)

    # update last recording list
    f = open(CACHE_FILE, "w")
    pickle.dump(recordings, f)
    f.close()
